{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this prject, we will walk through the full data science life cycle, from data cleaning and feature selection to machine learning. We will focus on credit modelling, a well known data science problem that focuses on modeling a borrower's credit risk. We'll be working with financial lending data from Lending Club. Lending Club is a marketplace for personal loans that matches borrowers who are seeking a loan with investors looking to lend money and make a return. \n",
    "\n",
    "Each borrower fills out a comprehensive application, providing their past financial history, the reason for the loan, and more. Lending Club evaluates each borrower's credit score using past historical data and assign an interest rate to the borrower. The interest rate is the percent in addition to the requested loan amount the borrower has to pay back. \n",
    "\n",
    "Approved loans are listed on the Lending Club website, where qualified investors can browse recently approved loans, the borrower's credit score, the purpose for the loan, and other information from the application. Once they're ready to back a loan, they select the amount of money they want to fund. Once a loan's requested amount is fully funded, the borrower receives the money they requested minus the origination fee that Lending Club charges.\n",
    "\n",
    "The borrower then makes monthly payments back to Lending Club either over 36 months or over 60 months. Lending Club redistributes these payments to the investors. This means that investors don't have to wait until the full amount is paid off to start to see money back. If a loan is fully paid off on time, the investors make a return which corresponds to the interest rate the borrower had to pay in addition the requested amount. Many loans aren't completely paid off on time, however, and some borrowers default on the loan.\n",
    "\n",
    "The data dictionary can be found in the project folder.\n",
    "\n",
    "_Goal: Build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Cleaning\n",
    "\n",
    "We'll focus on approved loans data from 2007 to 2011, since a good number of the loans have already finished. In the datasets for later years, many of the loans are current and still being paid off.\n",
    "\n",
    "To ensure that code runs fast on our platform, we first reduce the size of LoanStats3a.csv by:\n",
    "\n",
    " - removing the first line: contains the extraneous text Notes offered by Prospectus (https://www.lendingclub.com/info/prospectus.action) instead of the column titles, which prevents the dataset from being parsed by the pandas library properly\n",
    " - removing the desc column: contains a long text explanation for each loan\n",
    " - removing the url column: contains a link to each loan on Lending Club which can only be accessed with an investor account\n",
    " - removing all columns containing more than 50% missing values: allows us to move faster since we can spend less time trying to fill these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#remove first line\n",
    "loans_2007 = pd.read_csv('LoanStats3a.csv', skiprows=1)\n",
    "loans_2007.head()\n",
    "#drop desc and url cols\n",
    "loans_2007 = loans_2007.drop(['desc', 'url'], axis=1)\n",
    "#remove all columns containing more than 50% missing vals\n",
    "half_count = len(loans_2007) / 2\n",
    "loans_2007 = loans_2007.dropna(thresh=half_count, axis=1)\n",
    "#putting dataframe into csv file\n",
    "loans_2007.to_csv('loans_2007.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                            5000\n",
      "funded_amnt                          5000\n",
      "funded_amnt_inv                      4975\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "grade                                   B\n",
      "sub_grade                              B2\n",
      "emp_title                             NaN\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "issue_d                          Dec-2011\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "zip_code                            860xx\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "out_prncp                               0\n",
      "out_prncp_inv                           0\n",
      "total_pymnt                       5863.16\n",
      "total_pymnt_inv                   5833.84\n",
      "total_rec_prncp                      5000\n",
      "total_rec_int                      863.16\n",
      "total_rec_late_fee                      0\n",
      "recoveries                              0\n",
      "collection_recovery_fee                 0\n",
      "last_pymnt_d                     Jan-2015\n",
      "last_pymnt_amnt                    171.62\n",
      "last_credit_pull_d               Oct-2018\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               Individual\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "hardship_flag                           N\n",
      "disbursement_method                  Cash\n",
      "debt_settlement_flag                    N\n",
      "Name: 0, dtype: object 53\n"
     ]
    }
   ],
   "source": [
    "#display the first row and the number of columns\n",
    "print(loans_2007.iloc[0], loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "The Dataframe contains many columns and can be cumbersome to try to explore all at once. We'll break up the columns into 3 groups of 18 columns.\n",
    "\n",
    "**Group 1:**\n",
    "After analyzing each column, we can conclude that the following features need to be removed:\n",
    "\n",
    " - funded_amnt: leaks data from the future (after the loan is already started to be funded)\n",
    " - funded_amnt_inv: also leaks data from the future (after the loan is already started to be funded)\n",
    " - grade: contains redundant information as the interest rate column (int_rate)\n",
    " - sub_grade: also contains redundant information as the interest rate column (int_rate)\n",
    " - emp_title: requires other data and a lot of processing to potentially be useful\n",
    " - issue_d: leaks data from the future (after the loan is already completed funded)\n",
    " \n",
    "Recall that Lending Club assigns a grade and a sub-grade based on the borrower's interest rate. While the grade and sub_grade values are categorical, the int_rate column contains continuous values, which are better suited for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"funded_amnt\", \"funded_amnt_inv\", \"grade\", \n",
    "                              \"sub_grade\", \"emp_title\", \"issue_d\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group 2:**\n",
    "Within this group of columns, we need to drop the following columns:\n",
    "\n",
    " - zip_code: redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)\n",
    " - out_prncp: leaks data from the future, (after the loan already started to be paid off)\n",
    " - out_prncp_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - total_pymnt: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - total_pymnt_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - total_rec_prncp: also leaks data from the future, (after the loan already started to be paid off)\n",
    " \n",
    "The out_prncp and out_prncp_inv both describe the outstanding principal amount for a loan, which is the remaining amount the borrower still owes. These 2 columns as well as the total_pymnt column describe properties of the loan after it's fully funded and started to be paid off. This information isn't available to an investor before the loan is fully funded and we don't want to include it in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"zip_code\", \"out_prncp\", \"out_prncp_inv\", \n",
    "                              \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group 3:**\n",
    "In the last group of columns, we need to drop the following columns:\n",
    "\n",
    " - total_rec_int: leaks data from the future, (after the loan already started to be paid off)\n",
    " - total_rec_late_fee: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - recoveries: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - collection_recovery_fee: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - last_pymnt_d: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - last_pymnt_amnt: also leaks data from the future, (after the loan already started to be paid off)\n",
    " - hardship_flag: not in data dictionary.\n",
    " - disbursement_method: redundant infomation.\n",
    " - debt_settlement_flag: not in data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \n",
    "                              \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\",\n",
    "                             \"hardship_flag\", \"disbursement_method\", \"debt_settlement_flag\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                            5000\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                 Jan-1985\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                          83.7%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "last_credit_pull_d               Oct-2018\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               Individual\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object 32\n"
     ]
    }
   ],
   "source": [
    "#display first row and number of cols\n",
    "print(loans_2007.iloc[0],loans_2007.shape[1])\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Column\n",
    "We should use the loan_status column, since it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. Currently, this column contains text values and we need to convert it to a numerical one for training a model. Let's explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             34116\n",
       "Charged Off                                             5670\n",
       "Does not meet the credit policy. Status:Fully Paid      1988\n",
       "Does not meet the credit policy. Status:Charged Off      761\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the LendingClub website and some google searching, here are the explanations:\n",
    "\n",
    " - Fully Paid:\tloan has been fully paid off.\n",
    " - Charged Off: loan for which there is no longer a reasonable expectation of further payments.\n",
    " - Does not meet the credit policy: while the loan was paid off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    " - Does not meet the credit policy: while the loan was charged off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    " \n",
    "From the investor's perspective, we're interested in trying to predict which loans will be paid off on time and which ones won't be. Only the Fully Paid and Charged Off values describe the final outcome of the loan. Since we're interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a binary classification. We'll remove all the loans that don't contain either Fully Paid and Charged Off as the loan's status and then transform the Fully Paid values to 1 for the positive case and the Charged Off values to 0 for the negative case.\n",
    "\n",
    "_Note: There is a class imbalance between the positive and negative cases. While there are 34,116 loans that have been fully paid off, there are only 5,670 that were charged off. This class imbalance is a common problem in binary classification and during training, the model ends up having a strong bias towards predicting the class with more observations in the training set and will rarely predict the class with less observations. The stronger the imbalance, the more biased the model becomes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all rows from loans_2007 that contain values other than Fully Paid or Charged Off for the loan_status column.\n",
    "loans_2007 = loans_2007[(loans_2007['loan_status'] == \"Fully Paid\") | (loans_2007['loan_status'] == \"Charged Off\")]\n",
    "\n",
    "#create mapping dict for replacement\n",
    "status_replace = {\n",
    "    \"loan_status\" : {\n",
    "        \"Fully Paid\": 1,\n",
    "        \"Charged Off\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "#replace values according to mapping dict\n",
    "loans_2007 = loans_2007.replace(status_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "#remove any columns from loans_2007 that contain only one unique value\n",
    "orig_columns = loans_2007.columns\n",
    "drop_columns = []\n",
    "for col in orig_columns:\n",
    "    col_series = loans_2007[col].dropna().unique()\n",
    "    if len(col_series) == 1:\n",
    "        drop_columns.append(col)\n",
    "loans_2007 = loans_2007.drop(drop_columns, axis=1)\n",
    "#display drop_columns so we know which ones were removed\n",
    "print(drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Update:\n",
    "So far, we removed many columns that aren't useful for modeling. We also selected our target column and decided to focus our modeling efforts on binary classification. Next, we'll explore the individual features in greater depth and work towards training our first machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preperation\n",
    "\n",
    "We will now prepare the data for machine learning by focusing on handling missing values, converting categorical columns to numeric columns, and removing any other extraneous columns we encounter throughout this process.\n",
    "\n",
    "We start by computing the number of missing values and come up with a strategy for handling them. Then, we'll focus on the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                  0\n",
      "term                       0\n",
      "int_rate                   0\n",
      "installment                0\n",
      "emp_length              1078\n",
      "home_ownership             0\n",
      "annual_inc                 0\n",
      "verification_status        0\n",
      "loan_status                0\n",
      "purpose                    0\n",
      "title                     11\n",
      "addr_state                 0\n",
      "dti                        0\n",
      "delinq_2yrs                0\n",
      "earliest_cr_line           0\n",
      "inq_last_6mths             0\n",
      "open_acc                   0\n",
      "pub_rec                    0\n",
      "revol_bal                  0\n",
      "revol_util                50\n",
      "total_acc                  0\n",
      "last_credit_pull_d         2\n",
      "pub_rec_bankruptcies     697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#return the number of null values in each column\n",
    "null_counts = loans_2007.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While most of the columns have 0 missing values, 3 columns have 50 or less rows with missing values, and 1 column, pub_rec_bankruptcies, contains 697 rows with missing values. Let's remove columns entirely where more than 1% of the rows for that column contain a null value. In addition, we'll remove the remaining rows containing null values, except emp_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    11\n",
      "object     11\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#remove the pub_rec_bankruptcies column from loans\n",
    "loans = loans_2007.drop(\"pub_rec_bankruptcies\", axis=1)\n",
    "#remove all rows from loans containing any missing values\n",
    "loans = loans_2007.dropna(axis=0)\n",
    "#return the counts for each column data type\n",
    "print(loans.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the numerical columns can be used natively with scikit-learn, the object columns that contain text need to be converted to numerical data types. Let's return a new Dataframe containing just the object columns so we can explore them in more depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             term int_rate emp_length home_ownership verification_status  \\\n",
      "0       36 months   10.65%  10+ years           RENT            Verified   \n",
      "1       60 months   15.27%   < 1 year           RENT     Source Verified   \n",
      "2       36 months   15.96%  10+ years           RENT        Not Verified   \n",
      "3       36 months   13.49%  10+ years           RENT     Source Verified   \n",
      "4       60 months   12.69%     1 year           RENT     Source Verified   \n",
      "5       36 months    7.90%    3 years           RENT     Source Verified   \n",
      "6       60 months   15.96%    8 years           RENT        Not Verified   \n",
      "7       36 months   18.64%    9 years           RENT     Source Verified   \n",
      "8       60 months   21.28%    4 years            OWN     Source Verified   \n",
      "9       60 months   12.69%   < 1 year           RENT            Verified   \n",
      "10      60 months   14.65%    5 years            OWN        Not Verified   \n",
      "11      36 months   12.69%  10+ years            OWN     Source Verified   \n",
      "12      36 months   13.49%   < 1 year           RENT     Source Verified   \n",
      "13      36 months    9.91%    3 years           RENT     Source Verified   \n",
      "14      36 months   10.65%    3 years           RENT     Source Verified   \n",
      "15      36 months   16.29%   < 1 year           RENT        Not Verified   \n",
      "16      36 months   15.27%    4 years           RENT        Not Verified   \n",
      "17      36 months    6.03%  10+ years       MORTGAGE        Not Verified   \n",
      "18      36 months   11.71%     1 year       MORTGAGE            Verified   \n",
      "19      36 months    6.03%    6 years           RENT        Not Verified   \n",
      "20      60 months   15.27%    3 years           RENT            Verified   \n",
      "21      36 months   12.42%  10+ years           RENT            Verified   \n",
      "22      36 months   11.71%  10+ years            OWN     Source Verified   \n",
      "23      36 months   11.71%    5 years           RENT        Not Verified   \n",
      "24      36 months   11.71%     1 year           RENT        Not Verified   \n",
      "25      36 months    9.91%    2 years       MORTGAGE            Verified   \n",
      "26      36 months   14.27%    9 years           RENT        Not Verified   \n",
      "27      60 months   16.77%    2 years           RENT        Not Verified   \n",
      "28      36 months   11.71%  10+ years       MORTGAGE        Not Verified   \n",
      "29      36 months   11.71%   < 1 year           RENT     Source Verified   \n",
      "...           ...      ...        ...            ...                 ...   \n",
      "39067   36 months   11.97%   < 1 year          OTHER        Not Verified   \n",
      "39068   36 months    9.76%    7 years       MORTGAGE        Not Verified   \n",
      "39069   36 months    9.45%  10+ years           RENT        Not Verified   \n",
      "39070   36 months   11.34%     1 year          OTHER        Not Verified   \n",
      "39071   36 months   12.29%    4 years       MORTGAGE        Not Verified   \n",
      "39072   36 months   10.39%    6 years           RENT        Not Verified   \n",
      "39082   36 months    9.76%    4 years       MORTGAGE        Not Verified   \n",
      "39094   36 months   11.97%     1 year           RENT        Not Verified   \n",
      "39121   36 months   13.24%   < 1 year       MORTGAGE        Not Verified   \n",
      "39153   36 months   11.97%  10+ years            OWN        Not Verified   \n",
      "39207   36 months   10.71%  10+ years           RENT        Not Verified   \n",
      "39285   36 months   12.92%  10+ years       MORTGAGE        Not Verified   \n",
      "39289   36 months    9.76%    4 years           RENT        Not Verified   \n",
      "39320   36 months   13.55%   < 1 year           RENT        Not Verified   \n",
      "39328   36 months    9.45%   < 1 year       MORTGAGE        Not Verified   \n",
      "39357   36 months   10.46%  10+ years           RENT        Not Verified   \n",
      "39360   36 months   13.93%    5 years       MORTGAGE        Not Verified   \n",
      "39415   36 months   10.78%     1 year       MORTGAGE        Not Verified   \n",
      "39417   36 months    9.51%  10+ years           RENT        Not Verified   \n",
      "39431   36 months   10.78%  10+ years       MORTGAGE        Not Verified   \n",
      "39494   36 months   12.36%     1 year           RENT        Not Verified   \n",
      "39499   36 months   13.30%    9 years       MORTGAGE        Not Verified   \n",
      "39502   36 months    9.83%    7 years           RENT        Not Verified   \n",
      "39544   36 months    9.01%    6 years       MORTGAGE        Not Verified   \n",
      "39620   36 months   10.91%    2 years           RENT        Not Verified   \n",
      "39631   36 months   10.28%     1 year           RENT        Not Verified   \n",
      "39642   36 months   10.59%    3 years       MORTGAGE        Not Verified   \n",
      "39692   36 months   12.49%    8 years       MORTGAGE        Not Verified   \n",
      "39735   36 months   11.22%    2 years       MORTGAGE        Not Verified   \n",
      "39749   36 months   11.86%    2 years       MORTGAGE        Not Verified   \n",
      "\n",
      "                  purpose                                   title addr_state  \\\n",
      "0             credit_card                                Computer         AZ   \n",
      "1                     car                                    bike         GA   \n",
      "2          small_business                    real estate business         IL   \n",
      "3                   other                                personel         CA   \n",
      "4                   other                                Personal         OR   \n",
      "5                 wedding   My wedding loan I promise to pay back         AZ   \n",
      "6      debt_consolidation                                    Loan         NC   \n",
      "7                     car                         Car Downpayment         CA   \n",
      "8          small_business    Expand Business & Buy Debt Portfolio         CA   \n",
      "9                   other             Building my credit history.         TX   \n",
      "10     debt_consolidation              High intrest Consolidation         AZ   \n",
      "11     debt_consolidation                           Consolidation         CA   \n",
      "12     debt_consolidation                                 freedom         VA   \n",
      "13            credit_card                           citicard fund         IL   \n",
      "14                  other                              Other Loan         CA   \n",
      "15     debt_consolidation                 Debt Consolidation Loan         MO   \n",
      "16       home_improvement                                    Home         CA   \n",
      "17         major_purchase                                 Holiday         CT   \n",
      "18                medical                                 Medical         UT   \n",
      "19     debt_consolidation     lowerratemeanseasiertogetoutofdebt!         CA   \n",
      "20     debt_consolidation               Freedom From Credit Cards         TX   \n",
      "21     debt_consolidation                            Debt Cleanup         FL   \n",
      "22            credit_card                        Credit Card Loan         TX   \n",
      "23     debt_consolidation                      Debt Consolidation         CA   \n",
      "24         major_purchase                                    cash         CA   \n",
      "25            credit_card               No more credit card debt!         IL   \n",
      "26     debt_consolidation                           consolidation         NY   \n",
      "27                  other                                   Other         PA   \n",
      "28     debt_consolidation                      Debt Consolidation         FL   \n",
      "29            credit_card              Credit card repayment loan         MN   \n",
      "...                   ...                                     ...        ...   \n",
      "39067  debt_consolidation                      DEBT CONSOLIDATION         CA   \n",
      "39068               other                               Investing         OH   \n",
      "39069  debt_consolidation                                   drodo         NY   \n",
      "39070               other           Expanding my growing Business         AZ   \n",
      "39071  debt_consolidation             Operation Freedom From Debt         CA   \n",
      "39072               other                2002 Jayco Pop up camper         FL   \n",
      "39082         credit_card                  Refinance of Timeshare         DE   \n",
      "39094  debt_consolidation     Help consolidate and eliminate debt         NJ   \n",
      "39121  debt_consolidation                           consolidation         NY   \n",
      "39153    home_improvement                                  floors         AZ   \n",
      "39207  debt_consolidation                       Credit Card Debt!         NC   \n",
      "39285      small_business        Consolidate high interest loans          CA   \n",
      "39289         educational            Help pay for sons' education         CA   \n",
      "39320  debt_consolidation                       Debt cosilidation         NV   \n",
      "39328    home_improvement                                    home         CT   \n",
      "39357  debt_consolidation                      Consolidation Loan         MO   \n",
      "39360  debt_consolidation                   I need to consolidate         OH   \n",
      "39415      small_business              Expand Delivery Capability         NJ   \n",
      "39417  debt_consolidation                            Patti's loan         CA   \n",
      "39431             wedding     travel processing wedding over seas         NY   \n",
      "39494  debt_consolidation             Loan for Debt Consolidation         CT   \n",
      "39499         credit_card        Eliminate high rate credit cards         NY   \n",
      "39502         credit_card    Better habits and New Start for 2008         CA   \n",
      "39544         credit_card                      Debt Consolidation         IL   \n",
      "39620  debt_consolidation                  no credit cards for me         VA   \n",
      "39631  debt_consolidation      Want to pay off high intrest cards         VA   \n",
      "39642  debt_consolidation  Taking the First Step by Consolidating         AZ   \n",
      "39692  debt_consolidation                            Pay off debt         MD   \n",
      "39735  debt_consolidation    paying credit cards and doctor bill.         VA   \n",
      "39749  debt_consolidation  Merging 2 Accounts into one to save $$         IN   \n",
      "\n",
      "      earliest_cr_line revol_util last_credit_pull_d  \n",
      "0             Jan-1985      83.7%           Oct-2018  \n",
      "1             Apr-1999       9.4%           Oct-2016  \n",
      "2             Nov-2001      98.5%           Jun-2017  \n",
      "3             Feb-1996        21%           Apr-2016  \n",
      "4             Jan-1996      53.9%           Apr-2018  \n",
      "5             Nov-2004      28.3%           Feb-2017  \n",
      "6             Jul-2005      85.6%           Sep-2016  \n",
      "7             Jan-2007      87.5%           Dec-2014  \n",
      "8             Apr-2004      32.6%           Oct-2016  \n",
      "9             Sep-2004      36.5%           Dec-2016  \n",
      "10            Jan-1998      20.6%           Mar-2018  \n",
      "11            Oct-1989      67.1%           Aug-2013  \n",
      "12            Apr-2004      91.7%           Oct-2016  \n",
      "13            Jul-2003      43.1%           Apr-2017  \n",
      "14            May-1991      55.5%           Oct-2016  \n",
      "15            Sep-2007      81.5%           Oct-2018  \n",
      "16            Oct-1998      70.2%           Sep-2018  \n",
      "17            Aug-1993        16%           May-2014  \n",
      "18            Oct-2003     37.73%           Jul-2015  \n",
      "19            Jan-2001      23.1%           Feb-2016  \n",
      "20            Nov-1997      85.6%           Jun-2016  \n",
      "21            Feb-1983      90.3%           Feb-2017  \n",
      "22            Jul-1985      82.4%           Jan-2018  \n",
      "23            Apr-2003      91.8%           Mar-2014  \n",
      "24            Jun-2001      29.7%           Oct-2016  \n",
      "25            Feb-2002      93.9%           Sep-2012  \n",
      "26            Oct-2003      57.6%           Oct-2018  \n",
      "27            Oct-2003      59.5%           Oct-2016  \n",
      "28            Aug-1984      37.7%           Oct-2018  \n",
      "29            Nov-2006      59.1%           Jan-2015  \n",
      "...                ...        ...                ...  \n",
      "39067         Dec-2002      70.9%           Jul-2017  \n",
      "39068         Nov-1996      11.3%           Jan-2018  \n",
      "39069         Nov-1995      34.6%           Oct-2018  \n",
      "39070         Mar-1985      17.4%           Sep-2009  \n",
      "39071         Jan-2004      60.5%           Jun-2016  \n",
      "39072         Nov-1990      64.4%           Mar-2011  \n",
      "39082         Apr-1994      45.6%           Jul-2010  \n",
      "39094         May-1988      88.8%           Feb-2017  \n",
      "39121         Jan-1988        35%           Sep-2016  \n",
      "39153         May-1983      70.2%           Oct-2016  \n",
      "39207         Jul-1996      70.8%           Mar-2011  \n",
      "39285         Oct-1993      11.3%           Feb-2011  \n",
      "39289         May-1984      24.3%           Nov-2013  \n",
      "39320         May-1998      65.3%           Oct-2016  \n",
      "39328         Jan-1991      39.2%           Sep-2009  \n",
      "39357         Sep-2001        48%           Mar-2011  \n",
      "39360         Mar-2001      87.2%           Oct-2018  \n",
      "39415         Jan-1982      50.5%           Feb-2011  \n",
      "39417         Aug-1993      16.5%           Oct-2018  \n",
      "39431         Jun-2001       0.2%           Oct-2016  \n",
      "39494         Apr-1989      44.1%           Oct-2018  \n",
      "39499         Jan-1991      97.8%           Mar-2011  \n",
      "39502         Feb-1995      47.4%           Oct-2018  \n",
      "39544         Oct-1979      18.6%           Jun-2018  \n",
      "39620         Dec-2000      96.5%           Oct-2016  \n",
      "39631         Mar-2000      68.7%           Aug-2008  \n",
      "39642         Feb-1989        79%           Jun-2017  \n",
      "39692         Aug-1997      62.9%           Feb-2017  \n",
      "39735         Nov-1992      34.3%           Oct-2016  \n",
      "39749         Jul-2000      70.9%           Jul-2010  \n",
      "\n",
      "[37953 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "object_columns_df = loans.select_dtypes(include=['object'])\n",
    "print(object_columns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns seem like they represent categorical values, but we should confirm by checking the number of unique values in those columns:\n",
    "\n",
    " - home_ownership: home ownership status, can only be 1 of 4 categorical values according to the data dictionary\n",
    " - verification_status: indicates if income was verified by Lending Club\n",
    " - emp_length: number of years the borrower was employed upon time of application\n",
    " - term: number of payments on the loan, either 36 or 60\n",
    " - addr_state: borrower's state of residence\n",
    " - purpose: a category provided by the borrower for the loan request\n",
    " - title: loan title provided the borrower\n",
    " \n",
    "There are also some columns that represent numeric values, that need to be converted:\n",
    "\n",
    " - int_rate: interest rate of the loan in %\n",
    " - revol_util: revolving line utilization rate or the amount of credit the borrower is using relative to all available credit\n",
    " \n",
    "Based on the first row's values for purpose and title, it seems like these columns could reflect the same information. Let's explore the unique value counts separately to confirm if this is true.\n",
    "\n",
    "Lastly, some of the columns contain date values that would require a good amount of feature engineering for them to be potentially useful:\n",
    "\n",
    " - earliest_cr_line: The month the borrower's earliest reported credit line was opened\n",
    " - last_credit_pull_d: The most recent month Lending Club pulled credit for this loan\n",
    " \n",
    "Since these date features require some feature engineering for modeling purposes, let's remove these date columns from the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT        18091\n",
      "MORTGAGE    16991\n",
      "OWN          2775\n",
      "OTHER          96\n",
      "Name: home_ownership, dtype: int64\n",
      "Not Verified       15773\n",
      "Verified           12376\n",
      "Source Verified     9804\n",
      "Name: verification_status, dtype: int64\n",
      "10+ years    8778\n",
      "< 1 year     4410\n",
      "2 years      4305\n",
      "3 years      4033\n",
      "4 years      3390\n",
      "5 years      3246\n",
      "1 year       3148\n",
      "6 years      2195\n",
      "7 years      1749\n",
      "8 years      1458\n",
      "9 years      1241\n",
      "Name: emp_length, dtype: int64\n",
      " 36 months    27538\n",
      " 60 months    10415\n",
      "Name: term, dtype: int64\n",
      "CA    6825\n",
      "NY    3624\n",
      "FL    2727\n",
      "TX    2628\n",
      "NJ    1792\n",
      "IL    1475\n",
      "PA    1472\n",
      "VA    1345\n",
      "GA    1333\n",
      "MA    1275\n",
      "OH    1173\n",
      "MD    1009\n",
      "AZ     820\n",
      "WA     784\n",
      "CO     746\n",
      "NC     730\n",
      "CT     724\n",
      "MI     679\n",
      "MO     653\n",
      "MN     584\n",
      "NV     479\n",
      "SC     456\n",
      "OR     430\n",
      "WI     428\n",
      "AL     426\n",
      "LA     417\n",
      "KY     321\n",
      "OK     292\n",
      "KS     258\n",
      "UT     247\n",
      "AR     232\n",
      "DC     209\n",
      "RI     195\n",
      "NM     178\n",
      "WV     168\n",
      "HI     168\n",
      "NH     159\n",
      "DE     108\n",
      "MT      79\n",
      "WY      78\n",
      "AK      78\n",
      "SD      61\n",
      "VT      52\n",
      "MS      19\n",
      "TN      10\n",
      "ID       4\n",
      "IN       1\n",
      "IA       1\n",
      "NE       1\n",
      "Name: addr_state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#display unique value counts of the columnns that seem like they contain categorical values\n",
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for col in cols:\n",
    "    print(loans[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt_consolidation    17971\n",
      "credit_card            4906\n",
      "other                  3720\n",
      "home_improvement       2836\n",
      "major_purchase         2090\n",
      "small_business         1730\n",
      "car                    1480\n",
      "wedding                 915\n",
      "medical                 659\n",
      "moving                  548\n",
      "house                   364\n",
      "vacation                345\n",
      "educational             294\n",
      "renewable_energy         95\n",
      "Name: purpose, dtype: int64\n",
      "Debt Consolidation                                   2127\n",
      "Debt Consolidation Loan                              1691\n",
      "Personal Loan                                         620\n",
      "Consolidation                                         499\n",
      "debt consolidation                                    483\n",
      "Home Improvement                                      345\n",
      "Credit Card Consolidation                             342\n",
      "Debt consolidation                                    318\n",
      "Small Business Loan                                   317\n",
      "Credit Card Loan                                      307\n",
      "Personal                                              295\n",
      "Consolidation Loan                                    252\n",
      "Home Improvement Loan                                 239\n",
      "personal loan                                         212\n",
      "Wedding Loan                                          207\n",
      "Loan                                                  205\n",
      "personal                                              201\n",
      "consolidation                                         197\n",
      "Car Loan                                              195\n",
      "Other Loan                                            179\n",
      "Wedding                                               150\n",
      "Credit Card Payoff                                    149\n",
      "Credit Card Refinance                                 141\n",
      "Major Purchase Loan                                   137\n",
      "Consolidate                                           126\n",
      "Medical                                               114\n",
      "Credit Card                                           113\n",
      "home improvement                                      106\n",
      "My Loan                                                90\n",
      "Credit Cards                                           88\n",
      "                                                     ... \n",
      "Arm n Hammer                                            1\n",
      "Colsidation                                             1\n",
      "Honda Scooter                                           1\n",
      "Triniplace1                                             1\n",
      "cory                                                    1\n",
      "30 Day 401K Payoff                                      1\n",
      "Fertility treatment loan                                1\n",
      "NYC is expensive                                        1\n",
      "Moving from Student to Adult                            1\n",
      "streamline with lower apr                               1\n",
      "SETON HALL UNIVERSITY                                   1\n",
      "Harley Chopper                                          1\n",
      "GetoutofDebt                                            1\n",
      "Refinancing my AmericanExpress Card Debt                1\n",
      "Auto Loan for Used Car 1                                1\n",
      "Debt Consildation for Funeral Expenses and School       1\n",
      "Making Amends                                           1\n",
      "Retirement Loan Repayment                               1\n",
      "Adding a room for our Twins.                            1\n",
      "Athomas74                                               1\n",
      "Credit Card 16%                                         1\n",
      "Wedding Venue                                           1\n",
      "Credit Card Debt Annihilation                           1\n",
      "High Interest Consolidation                             1\n",
      "Daughter's college                                      1\n",
      "Mel's Financial Success Loan                            1\n",
      "MORE BANG FOR YOU HARD EARNED BUCK                      1\n",
      "Jumpstart on New Year's Resolution                      1\n",
      "36 month debt loan                                      1\n",
      "Gold                                                    1\n",
      "Name: title, Length: 18729, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#look at the unique value counts for the purpose and title columns to understand which column to keep\n",
    "print(loans[\"purpose\"].value_counts())\n",
    "print(loans[\"title\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The home_ownership, verification_status, emp_length, and term columns each contain a few discrete categorical values. We should encode these columns as dummy variables and keep them.\n",
    "\n",
    "It seems like the purpose and title columns do contain overlapping information but we'll keep the purpose column since it contains a few discrete values. In addition, the title column has data quality issues since many of the values are repeated with slight modifications (e.g. Debt Consolidation and Debt Consolidation Loan and debt consolidation).\n",
    "\n",
    "We can use the following mapping to clean the emp_length column:\n",
    "\n",
    " - \"10+ years\": 10\n",
    " - \"9 years\": 9\n",
    " - \"8 years\": 8\n",
    " - \"7 years\": 7\n",
    " - \"6 years\": 6\n",
    " - \"5 years\": 5\n",
    " - \"4 years\": 4\n",
    " - \"3 years\": 3\n",
    " - \"2 years\": 2\n",
    " - \"1 year\": 1\n",
    " - \"< 1 year\": 0\n",
    " - \"n/a\": 0\n",
    "We assume that people who may have been working more than 10 years have only really worked for 10 years. We also assume that people who've worked less than a year or if the information is not available that they've worked for 0. This is an imperfect general heuristic.\n",
    "\n",
    "Lastly, the addr_state column contains many discrete values and we'd need to add 49 dummy variable columns to use it for classification. This would make our Dataframe much larger and could slow down how quickly the code runs. Let's remove this column from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "loans = loans.drop([\"last_credit_pull_d\", \"earliest_cr_line\", \"addr_state\", \"title\"], axis=1)\n",
    "#removing '%' signs and converting to float\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(\"float\")\n",
    "#making categorical values numerical, for analysis\n",
    "loans = loans.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode applicable columns as dummy variables so we can use them in our model\n",
    "dummy_loans = pd.get_dummies(loans[[\"term\", \"verification_status\", \"purpose\", \"term\", 'home_ownership']])\n",
    "#concatenate result to loans dataframe\n",
    "loans = pd.concat([loans, dummy_loans], axis=1)\n",
    "#drop original columns\n",
    "loans = loans.drop([\"verification_status\", \"term\", \"purpose\", \"term\", \"home_ownership\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Update:\n",
    "\n",
    "We performed the last amount of data preparation necessary to start training machine learning models. We converted all of the columns to numerical values because those are the only type of value scikit-learn can work with. Now, we'll experiment with training models and evaluate accuracy using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "An error metric will help us figure out when our model is performing well, and when it's performing poorly. Our objective in this is to make money; we want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off. An error metric will help us determine if our algorithm will make us money or lose us money.\n",
    "\n",
    "In this case, we're primarily concerned with false positives and false negatives. Both of these are different types of misclassifications. With a false positive, we predict that a loan will be paid off on time, but it actually isn't. This costs us money, since we fund loans that lose us money. With a false negative, we predict that a loan won't be paid off on time, but it actually would be paid off on time. This loses us potential money, since we didn't fund a loan that actually would have been paid off.\n",
    "\n",
    "Since we're viewing this problem from the standpoint of a conservative investor, we need to treat false positives differently than false negatives. A conservative investor would want to minimize risk, and avoid false positives as much as possible. They'd be more okay with missing out on opportunities (false negatives) than they would be with funding a risky loan (false positives).\n",
    "\n",
    "It is important to always be aware of imbalanced classes in machine learning models, and to adjust your error metric accordingly. In this case, we don't want to use accuracy, and should instead use metrics that tell us the number of false positives and false negatives.\n",
    "\n",
    "This means that we should optimize for:\n",
    "\n",
    " - high recall (true positive rate)\n",
    " - low fall-out (false positive rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37953 entries, 0 to 39749\n",
      "Data columns (total 40 columns):\n",
      "loan_amnt                              37953 non-null float64\n",
      "int_rate                               37953 non-null float64\n",
      "installment                            37953 non-null float64\n",
      "emp_length                             37953 non-null int64\n",
      "annual_inc                             37953 non-null float64\n",
      "loan_status                            37953 non-null int64\n",
      "dti                                    37953 non-null float64\n",
      "delinq_2yrs                            37953 non-null float64\n",
      "inq_last_6mths                         37953 non-null float64\n",
      "open_acc                               37953 non-null float64\n",
      "pub_rec                                37953 non-null float64\n",
      "revol_bal                              37953 non-null float64\n",
      "revol_util                             37953 non-null float64\n",
      "total_acc                              37953 non-null float64\n",
      "pub_rec_bankruptcies                   37953 non-null float64\n",
      "term_ 36 months                        37953 non-null uint8\n",
      "term_ 60 months                        37953 non-null uint8\n",
      "verification_status_Not Verified       37953 non-null uint8\n",
      "verification_status_Source Verified    37953 non-null uint8\n",
      "verification_status_Verified           37953 non-null uint8\n",
      "purpose_car                            37953 non-null uint8\n",
      "purpose_credit_card                    37953 non-null uint8\n",
      "purpose_debt_consolidation             37953 non-null uint8\n",
      "purpose_educational                    37953 non-null uint8\n",
      "purpose_home_improvement               37953 non-null uint8\n",
      "purpose_house                          37953 non-null uint8\n",
      "purpose_major_purchase                 37953 non-null uint8\n",
      "purpose_medical                        37953 non-null uint8\n",
      "purpose_moving                         37953 non-null uint8\n",
      "purpose_other                          37953 non-null uint8\n",
      "purpose_renewable_energy               37953 non-null uint8\n",
      "purpose_small_business                 37953 non-null uint8\n",
      "purpose_vacation                       37953 non-null uint8\n",
      "purpose_wedding                        37953 non-null uint8\n",
      "term_ 36 months                        37953 non-null uint8\n",
      "term_ 60 months                        37953 non-null uint8\n",
      "home_ownership_MORTGAGE                37953 non-null uint8\n",
      "home_ownership_OTHER                   37953 non-null uint8\n",
      "home_ownership_OWN                     37953 non-null uint8\n",
      "home_ownership_RENT                    37953 non-null uint8\n",
      "dtypes: float64(13), int64(2), uint8(25)\n",
      "memory usage: 5.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loans.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, our cleaned dataset contains 40 columns, all of which are either the uint8, int64 or the float64 data type. There aren't any null values in any of the columns. This means that we can now apply any machine learning algorithm to our dataset.\n",
    "\n",
    "A good first algorithm to apply to binary classification problems is logistic regression, for the following reasons:\n",
    "\n",
    " - it's quick to train and we can iterate more quickly\n",
    " - it's less prone to overfitting than more complex models like decision trees\n",
    " - it's easy to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994319795512638\n",
      "0.9990259107734268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train_cols = loans.columns[loans.columns != 'loan_status']\n",
    "features = loans[train_cols]\n",
    "target = loans[\"loan_status\"]\n",
    "#fit a logistic regression to features and target\n",
    "lr.fit(features, target)\n",
    "#make predictions on features\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, even through we're not using accuracy as an error metric, the classifier is, and it isn't accounting for the imbalance in the classes. To get the classifier to correct for imbalanced classes, we will tell the classifier to penalize misclassifications of the less prevalent class more than the other class. This is easy to implement using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6286408532929407\n",
      "0.6146503019676602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#tell classifier to penalize misclassifications\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2376218877212913\n",
      "0.2433274887979739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#setting harsher penalties\n",
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest\n",
    "\n",
    "Let's try a different algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9689482154690903\n",
      "0.9649327878433664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.`\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Unfortunately, using a random forest classifier didn't improve our false positive rate. The model is likely weighting too heavily on the 1 class, and still mostly predicting 1s. We could fix this by applying a harsher penalty for misclassifications of 0s.\n",
    "\n",
    "Ultimately, our best model had a false positive rate of 24%, and a true positive rate of 23%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 24% of borrowers defaulting, and that the pool of 23% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model is better than that, although we're excluding more loans than a random strategy would. Given this, there's still quite a bit of room to improve:\n",
    "\n",
    "We can tweak the penalties further.\n",
    " - We can try models other than a random forest and logistic regression.\n",
    " - We can use some of the columns we discarded to generate better features.\n",
    " - We can ensemble multiple models to get more accurate predictions.\n",
    " - We can tune the parameters of the algorithm to achieve higher performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
